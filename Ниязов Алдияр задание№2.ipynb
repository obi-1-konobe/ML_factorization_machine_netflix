{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ниязов Алдияр М19-04\n",
    "Задание 2. Факторизационная машина. Netflix dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "из описания датасета опредлим количество пользователей, фильмов и рейтингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies = 17770\n",
    "n_users = 2649429\n",
    "n_rate = 100480508"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим горизонтальную размерность матрицы признаков после кодирования, как сумму количества пользователей и фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_movies + n_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен код парсера, который итерируясь по всем файлам исходников соберет общую матрицу данных в виде: one-hot-codding фильма, one-hot-codding фильма и соответствующий рейтинг. Так как матрица будет сильно разреженной, то для экономии памяти будем использовать формат csr_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определям директорию где находятся исходники\n",
    "directory = os.fsencode('training_set')\n",
    "\n",
    "# инициализируем нулями строку матрицы соответствующую одному наблюдению\n",
    "features = sparse.csr_matrix((1, n + 1), dtype=np.int8)\n",
    "\n",
    "files_end = 0\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "i = 0\n",
    "# итерируемся по файлам\n",
    "for file in os.listdir(directory):\n",
    "\n",
    "    filename = os.fsdecode(file)\n",
    "\n",
    "    with open(f'training_set/{filename}', 'r') as f:\n",
    "        text = f.readlines()\n",
    "    # определяем id фильма\n",
    "    movie_id = int(text[0].split(':')[0])\n",
    "    \n",
    "    # итерируемся по строкам в файле\n",
    "    for line in text[1:]:\n",
    "        info = line.split(',')\n",
    "        # определяем id пользователя и рейтинг\n",
    "        user_id = int(info[0])\n",
    "        rating = int(info[1])\n",
    "        # собираем данные в соответствующие массивы\n",
    "        data.append(1)\n",
    "        data.append(1)\n",
    "        data.append(rating)\n",
    "\n",
    "        row.append(i)\n",
    "        row.append(i)\n",
    "        row.append(i)\n",
    "        \n",
    "        # расположение в строке единички для фильма\n",
    "        col.append(movie_id - 1)\n",
    "        # так как в строке код пользователя следует после кода фильма,\n",
    "        # то id пользователя смещается на 17770\n",
    "        col.append(user_id + n_movies - 1)\n",
    "        # расположение в строке рейтинга\n",
    "        col.append(n)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    files_end += 1\n",
    "    if files_end % 1000 == 0:\n",
    "        # из собранных массивов определяем промежуточную спарс-матрицу\n",
    "        temp_matrix = sparse.csr_matrix((data, (row, col)), dtype=np.int8, shape=(i, n + 1))\n",
    "        # стакаем предыдущие значения итоговой матрицы с промежуточной\n",
    "        features = sparse.vstack([features, temp_matrix], dtype=np.int8)\n",
    "        print(files_end)\n",
    "        # обнуляем массивы\n",
    "        data = []\n",
    "        row = []\n",
    "        col = []\n",
    "        i = 0\n",
    "# стакаем остатки значений\n",
    "temp_matrix = sparse.csr_matrix((data, (row, col)), dtype=np.int8, shape=(i, n + 1))\n",
    "features = sparse.vstack([features, temp_matrix], dtype=np.int8)\n",
    "\n",
    "# сохраняем полученную матрицу данных на диск\n",
    "sparse.save_npz('sparse_matrix.npz', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sparse.load_npz('sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "перемешиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('shuffle_dataset.npz', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разделяем матрицу признаков и целевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = np.arange(dataset.shape[1])\n",
    "cols_to_keep = np.where(np.logical_not(np.in1d(all_cols, all_cols[:n])))[0]\n",
    "target = dataset[:, cols_to_keep]\n",
    "features = dataset[:, all_cols[:n]]\n",
    "\n",
    "sparse.save_npz('features.npz', features)\n",
    "sparse.save_npz('target.npz', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100480508x2667199 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 200961014 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проведения кросс-валидации разбиваем признаки и целевые значения на 5 частей примерно по 20млн. в каждой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sparse.load_npz('features.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('features_1.npz', features[:20000000])\n",
    "sparse.save_npz('features_2.npz', features[20000000:40000000])\n",
    "sparse.save_npz('features_3.npz', features[40000000:60000000])\n",
    "sparse.save_npz('features_4.npz', features[60000000:80000000])\n",
    "sparse.save_npz('features_5.npz', features[80000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = sparse.load_npz('target.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('target_1.npz', target[:20000000])\n",
    "sparse.save_npz('target_2.npz', target[20000000:40000000])\n",
    "sparse.save_npz('target_3.npz', target[40000000:60000000])\n",
    "sparse.save_npz('target_4.npz', target[60000000:80000000])\n",
    "sparse.save_npz('target_5.npz', target[80000000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## обучение модели и расчет метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучать факторизационную машину будем мини-батч градиентным спуском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent_1(X, y, n, lr, epoch_num):\n",
    "    # инициализируем матрицу факторов V, вектор весов признаков w и w0\n",
    "    V = np.random.random(size=(n, 3))\n",
    "    w0 = 0\n",
    "    w = np.random.random(size=(n, 1))\n",
    "    \n",
    "    # определяем эпохи\n",
    "    for epoch in range(epoch_num):\n",
    "        start = time.time()\n",
    "        # перемешиваем данные\n",
    "        X, y = shuffle(X, y)\n",
    "        # определяем размер батча\n",
    "        batch_size = 90000\n",
    "        # проходим батчами по датасету\n",
    "        for batch_idx in range(int(X.shape[0] / batch_size + 1)):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            batch = X[start_idx:end_idx]\n",
    "            y_batch = y[start_idx:end_idx]\n",
    "            \n",
    "            # рассчитываем постоянный компонент для экономии времени в дальнейшем\n",
    "            batch_dot_v = batch.dot(V)\n",
    "            # делаем прогноз\n",
    "            y_pred = w0 + batch.dot(w) + (0.5 * np.sum((batch_dot_v ** 2) - batch.dot(V ** 2), axis=1)).reshape(batch.shape[0], 1)\n",
    "            # рассчитываем градиент функции потерь (MSE)\n",
    "            dL_dy = 2 * (y_pred.reshape(y_batch.shape[0], 1) - y_batch.reshape(y_batch.shape[0], 1))\n",
    "            # рассчитываем градиенты по параметрам\n",
    "            dL_dw0 = dL_dy.mean()\n",
    "            dL_dw = batch.T.dot(dL_dy)\n",
    "            dL_dv = (batch.T.dot(batch_dot_v) - np.sum((batch.multiply(batch)), axis=0) * V) * dL_dw0 / batch.shape[0]\n",
    "            \n",
    "            # обновляем параметры\n",
    "            w0 -= lr * dL_dw0\n",
    "            w -= lr * dL_dw\n",
    "            V -= lr * dL_dv\n",
    "\n",
    "        stop = time.time()\n",
    "        print(f'epoch #{epoch} time: {stop - start} seconds')\n",
    "\n",
    "    return w0, w, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "определяем функции для расчета прогноза и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(X, w0, w, V):\n",
    "    return w0 + X.dot(w) + (0.5 * np.sum((X.dot(V) ** 2) - X.dot(V**2), axis=1)).reshape(X.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "так как моя реализация и ресурсы моей машины не позволяют реализовать полную кросс-валидацию в одном цикле, то будем производить ее по частям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_fold = [\n",
    "    'features_1.npz',\n",
    "    'features_2.npz',\n",
    "    'features_3.npz',\n",
    "    'features_4.npz',\n",
    "    'features_5.npz'\n",
    "]\n",
    "target_fold = [\n",
    "    'target_1.npz',\n",
    "    'target_2.npz',\n",
    "    'target_3.npz',\n",
    "    'target_4.npz',\n",
    "    'target_5.npz'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(feature_fold, target_fold, idx):\n",
    "    metrics = []\n",
    "    weights = []\n",
    "    \n",
    "    print(f\"\\n validation #{idx}\\n\")\n",
    "    data_train = []\n",
    "    target_train = []\n",
    "    # заружаем с диска часть данных для теста\n",
    "    data_test = sparse.load_npz(feature_fold.pop(idx))\n",
    "    target_test = sparse.load_npz(target_fold.pop(idx)).todense()\n",
    "    # объединяем оставшиеся части для обучения\n",
    "    for i in feature_fold:\n",
    "        data_train.append(sparse.load_npz(i))\n",
    "    for j in target_fold:\n",
    "        target_train.append(sparse.load_npz(j))\n",
    "\n",
    "    data_train = sparse.vstack(data_train)\n",
    "    target_train = sparse.vstack(target_train).todense()\n",
    "\n",
    "    # обучение факторизационной машины\n",
    "    w0, w, V = grad_descent_1(data_train, target_train, n, 0.0001, 5)\n",
    "    # расчет метрик\n",
    "    y_pred_train = get_prediction(data_train, w0, w, V)\n",
    "    y_pred_test = get_prediction(data_test, w0, w, V)\n",
    "    RMSE_train = get_rmse(target_train, y_pred_train)\n",
    "    RMSE_test = get_rmse(target_test, y_pred_test)\n",
    "    \n",
    "    # объединение результатов\n",
    "    metrics.append([RMSE_train, RMSE_test])\n",
    "    weights.append([w0, w, V])\n",
    "    print(f'RMSE train: {RMSE_train}')\n",
    "    print(f'RMSE test: {RMSE_test}')\n",
    "\n",
    "    return metrics, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " validation #0\n",
      "\n",
      "epoch #0 time: 825.5817205905914 seconds\n",
      "epoch #1 time: 1941.5300951004028 seconds\n",
      "epoch #2 time: 1867.6005456447601 seconds\n",
      "epoch #3 time: 1862.4598729610443 seconds\n",
      "epoch #4 time: 1818.3506247997284 seconds\n",
      "RMSE train: 1.0340010768324148\n",
      "RMSE test: 1.0354794566890753\n"
     ]
    }
   ],
   "source": [
    "metrics_0, weights_0 = cross_validation(feature_fold, target_fold, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " validation #1\n",
      "\n",
      "epoch #0 time: 778.4358777999878 seconds\n",
      "epoch #1 time: 1720.4833624362946 seconds\n",
      "epoch #2 time: 1798.7089726924896 seconds\n",
      "epoch #3 time: 2115.09365773201 seconds\n",
      "epoch #4 time: 2141.9165403842926 seconds\n",
      "RMSE train: 1.0340312433924348\n",
      "RMSE test: 1.0349081860912048\n"
     ]
    }
   ],
   "source": [
    "metrics_1, weights_1 = cross_validation(feature_fold, target_fold, idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " validation #2\n",
      "\n",
      "epoch #0 time: 882.2516176700592 seconds\n",
      "epoch #1 time: 2023.3425316810608 seconds\n",
      "epoch #2 time: 1870.3911740779877 seconds\n",
      "epoch #3 time: 2066.297188282013 seconds\n",
      "epoch #4 time: 1725.9794397354126 seconds\n",
      "RMSE train: 1.033638900611023\n",
      "RMSE test: 1.034918912076469\n"
     ]
    }
   ],
   "source": [
    "metrics_2, weights_2 = cross_validation(feature_fold, target_fold, idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " validation #3\n",
      "\n",
      "epoch #0 time: 900.4800293445587 seconds\n",
      "epoch #1 time: 1717.0699076652527 seconds\n",
      "epoch #2 time: 1716.3005232810974 seconds\n",
      "epoch #3 time: 2793.074732065201 seconds\n",
      "epoch #4 time: 2427.108398914337 seconds\n",
      "RMSE train: 1.0335742903131206\n",
      "RMSE test: 1.0343878814603689\n"
     ]
    }
   ],
   "source": [
    "metrics_3, weights_3 = cross_validation(feature_fold, target_fold, idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " validation #4\n",
      "\n",
      "epoch #0 time: 753.9998817443848 seconds\n",
      "epoch #1 time: 1195.5279302597046 seconds\n",
      "epoch #2 time: 2077.0152752399445 seconds\n",
      "epoch #3 time: 2307.4723348617554 seconds\n",
      "epoch #4 time: 2106.04757976532 seconds\n",
      "RMSE train: 1.033992909612587\n",
      "RMSE test: 1.034857833837001\n"
     ]
    }
   ],
   "source": [
    "metrics_4, weights_4 = cross_validation(feature_fold, target_fold, idx=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## представление результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество эпох: 5\n",
    "размер батча: 90 000\n",
    "скорость обучения: 0.0001\n",
    "количество фолдов: 5\n",
    "количество признаков: 2 667 199\n",
    "количество факторов: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metrics = {\n",
    "        'fold 1': metrics_0, \n",
    "        'fold 2': metrics_1, \n",
    "        'fold 3': metrics_2, \n",
    "        'fold 4': metrics_3, \n",
    "        'fold 5': metrics_4,\n",
    "        'mean': mean,\n",
    "        'std': std\n",
    "       }\n",
    "\n",
    "df_metrics = pd.DataFrame(data_metrics, index=['RMSE train', 'RMSE test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold 1</th>\n",
       "      <th>fold 2</th>\n",
       "      <th>fold 3</th>\n",
       "      <th>fold 4</th>\n",
       "      <th>fold 5</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>RMSE train</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>1.0336</td>\n",
       "      <td>1.0335</td>\n",
       "      <td>1.0339</td>\n",
       "      <td>1.03380</td>\n",
       "      <td>0.00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RMSE test</td>\n",
       "      <td>1.0354</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>1.0343</td>\n",
       "      <td>1.0348</td>\n",
       "      <td>1.03486</td>\n",
       "      <td>0.00035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fold 1  fold 2  fold 3  fold 4  fold 5     mean      std\n",
       "RMSE train  1.0340  1.0340  1.0336  1.0335  1.0339  1.03380  0.00021\n",
       "RMSE test   1.0354  1.0349  1.0349  1.0343  1.0348  1.03486  0.00035"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
